{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc51bea-3929-4d23-b769-1404dae34b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d5ad4e-f31f-42fc-8bff-2936b68e457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils.download import download_3d_similar_molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ac46ea-9e95-4d95-814f-38280b20fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "notebook = os.path.join(\".\")\n",
    "temp = os.path.join(notebook, \".temp\") # use to download temporary files (temporary downloads).\n",
    "if not os.path.exists(temp):\n",
    "    os.makedirs(temp)\n",
    "\n",
    "model_path = os.path.join(notebook, '..', 'models', 'reinvent.prior')\n",
    "vsflow_path = os.path.join(notebook, '..', 'vsflow')\n",
    "vsflow = os.path.join(vsflow_path, 'vsflow')\n",
    "vsflow_database_path = os.path.join(temp, 'vsflow_db.vsdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52747510-b8b9-41ce-90a8-8a9ac3226194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Smiles\n",
    "input_smiles = \"CC1(OC2C(OC(C2O1)(C#N)C3=CC=C4N3N=CN=C4N)CO)C\"\n",
    "filename = \"remdesivir.json\"\n",
    "similar_str_smiles_path = os.path.join(temp, filename)\n",
    "\n",
    "download_3d_similar_molecules(input_smiles, similar_str_smiles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc492367-622a-42ca-b13e-902ca2db16e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1(C)CN(C2=CC=NC(N)=C2C#N)C[C@H](CO)O1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1(C)CN(C2=CC=NC(N)=C2C#N)CC(CO)O1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1(C)CN(C2=CC=NC(N)=C2C#N)C[C@@H](CO)O1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1(C)O[C@H]2[C@@H](O1)[C@@H](n1cnc3c1ncnc3N)O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1(C)CN(C2=CC=NC3=C(C#N)C=NN23)C[C@H](CO)O1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@H](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0              CC1(C)CN(C2=CC=NC(N)=C2C#N)C[C@H](CO)O1\n",
       "1                  CC1(C)CN(C2=CC=NC(N)=C2C#N)CC(CO)O1\n",
       "2             CC1(C)CN(C2=CC=NC(N)=C2C#N)C[C@@H](CO)O1\n",
       "3    CC1(C)O[C@H]2[C@@H](O1)[C@@H](n1cnc3c1ncnc3N)O...\n",
       "4         CC1(C)CN(C2=CC=NC3=C(C#N)C=NN23)C[C@H](CO)O1\n",
       "..                                                 ...\n",
       "495  CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@@H]...\n",
       "496  CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@@H]...\n",
       "497  CCC1(C)CN(c2ncnc3c2ncn3[C@@H]2O[C@H](CO)[C@H](...\n",
       "498  Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1...\n",
       "499  Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the downloaded 3d similar structures.\n",
    "\n",
    "similar_str_smiles = {}\n",
    "with open(similar_str_smiles_path) as reader:\n",
    "    similar_str_smiles = json.load(reader)\n",
    "\n",
    "filtered_smiles = []\n",
    "for smiles in similar_str_smiles['neighbors']:\n",
    "    # Only taking smiles that has tanimoto score less than 0.70\n",
    "    if smiles['Morgan Tanimoto'] < 0.70:\n",
    "        filtered_smiles.append(smiles['smiles'])\n",
    "\n",
    "df = pd.DataFrame(data=filtered_smiles)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4440a3ef-7da6-4360-a610-7082c795a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (80%), Validation(10%), Test(10%)\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Define your split sizes\n",
    "train_size = int(0.8 * len(df))\n",
    "valid_size = int(0.1 * len(df))\n",
    "\n",
    "# Split your DataFrame\n",
    "train_df = df[:train_size]\n",
    "valid_df = df[train_size:(train_size + valid_size)]\n",
    "test_df = df[(train_size + valid_size):]\n",
    "\n",
    "train_set_file = os.path.join(temp, 'training.smi')\n",
    "valid_set_file = os.path.join(temp, 'validation.smi')\n",
    "test_set_file = os.path.join(temp, 'test.smi')\n",
    "\n",
    "\n",
    "train_df.to_csv(train_set_file, sep=\"\\t\", index=False, header=False)\n",
    "valid_df.to_csv(valid_set_file, sep=\"\\t\", index=False, header=False)\n",
    "test_df.to_csv(test_set_file, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a631f4-7ace-400c-8f6b-0bec6da81642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning config. (Ref: https://github.com/MolecularAI/REINVENT4/blob/main/notebooks/Reinvent_TLRL.py)\n",
    "\n",
    "config_filename = os.path.join(temp, 'config.json')\n",
    "new_model_path = os.path.join(temp, 'temp.model')\n",
    "reinvet_transfer_learning_parameter = {\n",
    "    \"run_type\": \"transfer_learning\",\n",
    "    \"device\": \"cpu\",\n",
    "    \"tb_logdir\": os.path.join(temp, 'tb_TL'),\n",
    "    \"parameters\": {\n",
    "        \"num_epochs\": 20,\n",
    "        \"save_every_n_epochs\": 2,\n",
    "        \"batch_size\": 50,\n",
    "        \"sample_batch_size\": 500,\n",
    "        \"input_model_file\": model_path,\n",
    "        \"output_model_file\": new_model_path,\n",
    "        \"smiles_file\": train_set_file,\n",
    "        \"validation_smiles_file\": valid_set_file,\n",
    "        \"standardize_smiles\": True,\n",
    "        \"randomize_smiles\": False,\n",
    "        \"randomize_all_smiles\": False,\n",
    "        \"internal_diversity\": True,\n",
    "        \"pairs\": {\n",
    "            \"type\": \"tanimoto\",\n",
    "            \"upper_threshold\": 0.6,\n",
    "            \"lower_threshold\": 0.0,\n",
    "            \"min_cardinality\": 1,\n",
    "            \"max_cardinality\": 199\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(config_filename, \"w\") as writer:\n",
    "    json.dump(reinvet_transfer_learning_parameter, writer, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ddc710b-e44a-442c-ad52-1cee6c11514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:12:22 <INFO> Started REINVENT 4.3.5 (C) AstraZeneca 2017, 2023 on 2024-07-10\n",
      "22:12:22 <INFO> Command line: C:\\Users\\ankit\\.conda\\envs\\reinvent-transfer-learning\\Scripts\\reinvent .\\.temp\\config.json -f json\n",
      "22:12:22 <INFO> User ankit on host Ank\n",
      "22:12:22 <INFO> Python version 3.11.9\n",
      "22:12:22 <INFO> PyTorch version 2.2.1+cu121, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0\n",
      "22:12:22 <INFO> PyTorch compiled with CUDA version 12.1\n",
      "22:12:22 <INFO> RDKit version 2023.09.5\n",
      "22:12:22 <INFO> Platform Windows-10-10.0.26244-SP0\n",
      "22:12:22 <INFO> Number of PyTorch CUDA devices 1\n",
      "22:12:22 <INFO> Using CPU AMD64 Family 25 Model 80 Stepping 0, AuthenticAMD\n",
      "22:12:22 <INFO> Writing TensorBoard summary to D:\\projects\\github\\reinvent-transfer-learning\\notebooks\\.temp\\tb_TL\n",
      "22:12:22 <INFO> Starting Transfer Learning\n",
      "22:12:22 <INFO> D:\\projects\\github\\reinvent-transfer-learning\\models\\reinvent.prior has valid hash:\n",
      "{ 'comments': [],\n",
      "  'creation_date': 0,\n",
      "  'date_format': 'UNIX epoch',\n",
      "  'hash_id': '173568c36e1fc3d95cab289c7d31ce0b',\n",
      "  'hash_id_format': 'xxhash.xxh3_128_hex 3.4.1',\n",
      "  'model_id': '55d68f8a81c04f5a86304ebe1723a0ea',\n",
      "  'model_id_format': 'uuid.uuid4 3.10.12',\n",
      "  'origina_data_source': 'ChEMBL 25',\n",
      "  'updates': []}\n",
      "22:12:22 <INFO> Number of network parameters: 5,805,602\n",
      "22:12:22 <INFO> Using generator Reinvent\n",
      "22:12:22 <INFO> Applying filter default to input SMILES\n",
      "22:12:23 <WARN> \"default\" filter: CC1(C)CN(C2=CC3=C(C=N2)C(I)=NN3)C[C@@H](CO)O1 is invalid\n",
      "22:12:23 <WARN> \"default\" filter: Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@H]2O[P@](=O)([O-])O[C@H]21 is invalid\n",
      "22:12:23 <WARN> \"default\" filter: Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H]2O[P@](=O)([O-])O[C@H]12 is invalid\n",
      "22:12:23 <WARN> \"default\" filter: CC1(C)CN(C2=CC3=C(C=N2)C(I)=NN3)CC(CO)O1 is invalid\n",
      "22:12:23 <WARN> \"default\" filter: CC1(C)CN(C2=CC3=C(C=N2)C(I)=NN3)C[C@H](CO)O1 is invalid\n",
      "22:12:23 <INFO> Read 172 input SMILES from D:\\projects\\github\\reinvent-transfer-learning\\notebooks\\.temp\\training.smi\n",
      "22:12:23 <WARN> \"default\" filter: Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H]2O[P@](=O)([O-])O[C@@H]12 is invalid\n",
      "22:12:23 <INFO> Read 40 validation SMILES from D:\\projects\\github\\reinvent-transfer-learning\\notebooks\\.temp\\validation.smi\n",
      "\n",
      "|\u001b[32m          \u001b[0m|00:00\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: |\u001b[32m          \u001b[0m|00:00\n",
      "Epoch 1: |\u001b[32m5         \u001b[0m|00:01\n",
      "Epoch 2: |\u001b[32m5         \u001b[0m|00:01\n",
      "Epoch 2: |\u001b[32m#         \u001b[0m|00:08\n",
      "Epoch 3: |\u001b[32m#         \u001b[0m|00:08\n",
      "Epoch 3: |\u001b[32m#5        \u001b[0m|00:10\n",
      "Epoch 4: |\u001b[32m#5        \u001b[0m|00:10\n",
      "Epoch 4: |\u001b[32m##        \u001b[0m|00:16\n",
      "Epoch 5: |\u001b[32m##        \u001b[0m|00:16\n",
      "Epoch 5: |\u001b[32m##5       \u001b[0m|00:18\n",
      "Epoch 6: |\u001b[32m##5       \u001b[0m|00:18\n",
      "Epoch 6: |\u001b[32m###       \u001b[0m|00:24\n",
      "Epoch 7: |\u001b[32m###       \u001b[0m|00:24\n",
      "Epoch 7: |\u001b[32m###5      \u001b[0m|00:26\n",
      "Epoch 8: |\u001b[32m###5      \u001b[0m|00:26\n",
      "Epoch 8: |\u001b[32m####      \u001b[0m|00:32\n",
      "Epoch 9: |\u001b[32m####      \u001b[0m|00:32\n",
      "Epoch 9: |\u001b[32m####5     \u001b[0m|00:33\n",
      "Epoch 10: |\u001b[32m####5     \u001b[0m|00:33\n",
      "Epoch 10: |\u001b[32m#####     \u001b[0m|00:40\n",
      "Epoch 11: |\u001b[32m#####     \u001b[0m|00:40\n",
      "Epoch 11: |\u001b[32m#####5    \u001b[0m|00:41\n",
      "Epoch 12: |\u001b[32m#####5    \u001b[0m|00:41\n",
      "Epoch 12: |\u001b[32m######    \u001b[0m|00:48\n",
      "Epoch 13: |\u001b[32m######    \u001b[0m|00:48\n",
      "Epoch 13: |\u001b[32m######5   \u001b[0m|00:49\n",
      "Epoch 14: |\u001b[32m######5   \u001b[0m|00:49\n",
      "Epoch 14: |\u001b[32m#######   \u001b[0m|00:55\n",
      "Epoch 15: |\u001b[32m#######   \u001b[0m|00:55\n",
      "Epoch 15: |\u001b[32m#######5  \u001b[0m|00:57\n",
      "Epoch 16: |\u001b[32m#######5  \u001b[0m|00:57\n",
      "Epoch 16: |\u001b[32m########  \u001b[0m|01:03\n",
      "Epoch 17: |\u001b[32m########  \u001b[0m|01:03\n",
      "Epoch 17: |\u001b[32m########5 \u001b[0m|01:05\n",
      "Epoch 18: |\u001b[32m########5 \u001b[0m|01:05\n",
      "Epoch 18: |\u001b[32m######### \u001b[0m|01:11\n",
      "Epoch 19: |\u001b[32m######### \u001b[0m|01:11\n",
      "Epoch 19: |\u001b[32m#########5\u001b[0m|01:12\n",
      "Epoch 20: |\u001b[32m#########5\u001b[0m|01:12\n",
      "Epoch 20: |\u001b[32m##########\u001b[0m|01:19\n",
      "Epoch 20: |\u001b[32m##########\u001b[0m|01:19\n",
      "\n",
      "0it [01:19, ?it/s]\n",
      "22:13:43 <INFO> Best validation loss (8.575) was at epoch 20\n",
      "22:13:43 <WARN> Best validation loss occured at the last epoch. Consider to train your model for more epochs\n",
      "22:13:43 <INFO> Finished REINVENT on 2024-07-10\n"
     ]
    }
   ],
   "source": [
    "# Transfer Learning.\n",
    "\n",
    "!reinvent $config_filename -f json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18763d0-840a-4680-b896-b3b7a2f4ec31",
   "metadata": {},
   "source": [
    "![A Mean Loss](./a_mean_loss.png)\n",
    "![B Fraction Valid](b_fraction_valid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a8652c-19ea-478d-9f47-0c36d545000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:14:46 <INFO> Started REINVENT 4.3.5 (C) AstraZeneca 2017, 2023 on 2024-07-10\n",
      "22:14:46 <INFO> Command line: C:\\Users\\ankit\\.conda\\envs\\reinvent-transfer-learning\\Scripts\\reinvent .\\.temp\\_config.json -f json\n",
      "22:14:46 <INFO> User ankit on host Ank\n",
      "22:14:46 <INFO> Python version 3.11.9\n",
      "22:14:46 <INFO> PyTorch version 2.2.1+cu121, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0\n",
      "22:14:46 <INFO> PyTorch compiled with CUDA version 12.1\n",
      "22:14:46 <INFO> RDKit version 2023.09.5\n",
      "22:14:46 <INFO> Platform Windows-10-10.0.26244-SP0\n",
      "22:14:46 <INFO> Number of PyTorch CUDA devices 1\n",
      "22:14:46 <INFO> Using CPU AMD64 Family 25 Model 80 Stepping 0, AuthenticAMD\n",
      "22:14:46 <INFO> Starting Sampling\n",
      "22:14:46 <ERRO> D:\\projects\\github\\reinvent-transfer-learning\\notebooks\\.temp\\temp.model has invalid hash:\n",
      "{ 'comments': [],\n",
      "  'creation_date': 0,\n",
      "  'date_format': 'UNIX epoch',\n",
      "  'hash_id': '173568c36e1fc3d95cab289c7d31ce0b',\n",
      "  'hash_id_format': 'xxhash.xxh3_128_hex 3.4.1',\n",
      "  'model_id': '55d68f8a81c04f5a86304ebe1723a0ea',\n",
      "  'model_id_format': 'uuid.uuid4 3.10.12',\n",
      "  'origina_data_source': 'ChEMBL 25',\n",
      "  'updates': []}\n",
      "22:14:46 <INFO> Number of network parameters: 5,805,602\n",
      "22:14:46 <INFO> Using generator Reinvent\n",
      "22:14:46 <INFO> Writing sampled SMILES to CSV file .\\.temp\\output.csv\n",
      "22:14:46 <INFO> Sampling 100 SMILES from model .\\.temp\\temp.model\n",
      "22:14:47 <INFO> Time taken in seconds: 0\n",
      "22:14:47 <INFO> Finished REINVENT on 2024-07-10\n"
     ]
    }
   ],
   "source": [
    "# Running new model\n",
    "new_model_config_path = os.path.join(temp, '_config.json')\n",
    "output_smiles = os.path.join(temp, 'output.csv')\n",
    "config = {\n",
    "    \"run_type\": \"sampling\",\n",
    "    \"device\": \"cpu\",\n",
    "    \"parameters\": {\n",
    "        \"model_file\": new_model_path,\n",
    "        \"output_file\": output_smiles,\n",
    "        \"num_smiles\": 100,\n",
    "        \"unique_molecules\": True,\n",
    "        \"randomize_smiles\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(new_model_config_path, \"w\") as writer:\n",
    "    json.dump(config, writer, indent=2)\n",
    "\n",
    "\n",
    "!reinvent $new_model_config_path -f json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
